---
title: "05_Reproducible_Research_Course_Project_2"
author: "Alexander Cormack"
date: "2023-05-20"
output: html_document
---

# Project description

## Introduction

Storms and other severe weather events can cause both public health and economic problems for communities and municipalities. Many severe events can result in fatalities, injuries, and property damage, and preventing such outcomes to the extent possible is a key concern.

This project involves exploring the U.S. National Oceanic and Atmospheric Administration's (NOAA) storm database. This database tracks characteristics of major storms and weather events in the United States, including when and where they occur, as well as estimates of any fatalities, injuries, and property damage.

## Data

The data for this assignment come in the form of a comma-separated-value file compressed via the bzip2 algorithm to reduce its size. You can download the file from the course web site:

* [Storm Data](https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2) [47Mb]

There is also some documentation of the database available. Here you will find how some of the variables are constructed/defined.

* National Weather Service [Storm Data Documentation](https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf)

* National Climatic Data Center Storm Events [FAQ](https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2FNCDC Storm Events-FAQ Page.pdf)

The events in the database start in the year 1950 and end in November 2011. In the earlier years of the database there are generally fewer events recorded, most likely due to a lack of good records. More recent years should be considered more complete.

## Review criteria

1.	Has either a (1) valid RPubs URL pointing to a data analysis document for this assignment been submitted; or (2) a complete PDF file presenting the data analysis been uploaded?
2.	Is the document written in English?
3.	Does the analysis include description and justification for any data transformations?
4.	Does the document have a title that briefly summarizes the data analysis?
5.	Does the document have a synopsis that describes and summarizes the data analysis in less than 10 sentences?
6.	Is there a section titled "Data Processing" that describes how the data were loaded into R and processed for analysis?
7.	Is there a section titled "Results" where the main results are presented?
8.	Is there at least one figure in the document that contains a plot?
9.	Are there at most 3 figures in this document?
10.	Does the analysis start from the raw data file (i.e. the original .csv.bz2 file)?
11.	Does the analysis address the question of which types of events are most harmful to population health?
12.	Does the analysis address the question of which types of events have the greatest economic consequences?
13.	Do all the results of the analysis (i.e. figures, tables, numerical summaries) appear to be reproducible?
14.	Do the figure(s) have descriptive captions (i.e. there is a description near the figure of what is happening in the figure)?
15.	As far as you can determine, does it appear that the work submitted for this project is the work of the student who submitted it?


## Assignment

The basic goal of this assignment is to explore the NOAA Storm Database and answer some basic questions about severe weather events. You must use the database to answer the questions below and show the code for your entire analysis. Your analysis can consist of tables, figures, or other summaries. You may use any R package you want to support your analysis.

### Questions

Your data analysis must address the following questions:

1.	Across the United States, which types of events (as indicated in the <span style="color: red;">EVTYPE</span> variable) are most harmful with respect to population health?
2.	Across the United States, which types of events have the greatest economic consequences?

Consider writing your report as if it were to be read by a government or municipal manager who might be responsible for preparing for severe weather events and will need to prioritize resources for different types of events. However, there is no need to make any specific recommendations in your report.

### Requirements

For this assignment you will need some specific tools

* RStudio: You will need RStudio to publish your completed analysis document to RPubs. You can also use RStudio to edit/write your analysis.
* knitr: You will need the knitr package in order to compile your R Markdown document and convert it to HTML

## Document Layout

* Language: Your document should be written in English.
* Title: Your document should have a title that briefly summarizes your data analysis
* Synopsis: Immediately after the title, there should be a synopsis which describes and summarizes your analysis in at most 10 complete sentences.
* There should be a section titled Data Processing which describes (in words and code) how the data were loaded into R and processed for analysis. In particular, your analysis must start from the raw CSV file containing the data. You cannot do any preprocessing outside the document. If preprocessing is time-consuming you may consider using the <span style="color: red;">cache = TRUE</span> option for certain code chunks.
* There should be a section titled Results in which your results are presented.
* You may have other sections in your analysis, but Data Processing and Results are required.
* The analysis document must have at least one figure containing a plot.
* Your analysis must have no more than three figures. Figures may have multiple plots in them (i.e. panel plots), but there cannot be more than three figures total.
* You must show all your code for the work in your analysis document. This may make the document a bit verbose, but that is okay. In general, you should ensure that <span style="color: red;">echo = TRUE</span> for every code chunk (this is the default setting in knitr).

## Publishing Your Analysis

For this assignment you will need to publish your analysis on RPubs.com. If you do not already have an account, then you will have to create a new account. After you have completed writing your analysis in RStudio, you can publish it to RPubs by doing the following:

1.	In RStudio, make sure your R Markdown document (<span style="color: red;">.Rmd</span>) document is loaded in the editor
2.	Click the <span style="color: red;">Knit HTML</span> button in the doc toolbar to preview your document.
3.	In the preview window, click the <span style="color: red;">Publish</span> button.

Once your document is published to RPubs, you should get a unique URL to that document. Make a note of this URL as you will need it to submit your assignment.

NOTE: If you are having trouble connecting with RPubs due to proxy-related or other issues, you can upload your final analysis document file as a PDF to Coursera instead.

## Submitting Your Assignment

In order to submit this assignment, you must copy the RPubs URL for your completed data analysis document in to the peer assessment question.
If you choose to submit as a PDF, please insert an obvious placeholder URL (e.g. https://google.com) in order to allow submission.


# Title




# Synopsis






# Data Processing

As a first step the code chunks options in this R markdowwn document are set to echo = TRUE.

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
```

The libraries that we will be used for this report are also loaded.

```{r load libraries, message = FALSE}
library(dplyr)
# library(ggplot2)
# library(lubridate)
```



Here  the contents of the zip file are downloaded and read into a data frame. N.B. the 'read.csv' command can handle compressed files automatically.

```{r download and read file, cache = TRUE, message = FALSE}

url <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
destfile <- "./data/05_assignment2_data.csv.bz2"
download.file(url, destfile)
storm_data <- read.csv("./data/05_assignment2_data.csv.bz2")
```

The data processing begins with an analysis of the structure of the data.

```{r data structure}
str(storm_data)
```

There are 902297 rows and 37 columns. The task at hand is the following:

1.	Across the United States, which types of events (as indicated in the EVTYPE variable) are most harmful with respect to population health?
2.	Across the United States, which types of events have the greatest economic consequences?

So the columns of interest are EVTYPE, FATALITIES, INJURIES, PROPDMG, PROPDMGEXP, CROPDMG and CROPDMGEXP.

First up is to check for anomalies (e.g. duplicate values) in the EVTYPE column.

```{r check EVTYPE column}
sort(unique(storm_data$EVTYPE))
```

The National Weather Service Storm Data Documentation lists 48 event types, whereas the data set has 985 unique values. Some of the causes include extra white space, lowercase/uppercase duplicates, sub-classifications (e.g. WET MICROBURST should be classified as THUNDERSTORM WIND), spelling errors or outright anomalies (see for example the many instances of "Summary").

The code below deals with the duplicates.

```{r remove duplicates, message = FALSE}
storm_data$EVTYPE <- trimws(storm_data$EVTYPE) ## trim leading and trailing whitespace
storm_data$EVTYPE <- gsub("\\s+"," ", storm_data$EVTYPE)  ## remove extra whitespace between words
storm_data$EVTYPE <- toupper(storm_data$EVTYPE)  ## convert all strings to uppercase
storm_data$EVTYPE[storm_data$EVTYPE == "ABNORMAL WARMTH"] <- "HEAT"  ## abnormal warmth likely falls under the classification heat

storm_data$EVTYPE[storm_data$EVTYPE == "ABNORMALLY DRY"] <- "DROUGHT"  ## abnormally dry likely falls under the classification drought

storm_data$EVTYPE[storm_data$EVTYPE == "ABNORMALLY WET"] <- "HEAVY RAIN"  ## abnormally wet likely falls under the classification heat

storm_data$EVTYPE[storm_data$EVTYPE == "ACCUMULTAED SNOWFALL"] <- "HEAVY SNOW"  ## accumulated snow likely falls under the classification heavy snow

storm_data$EVTYPE[storm_data$EVTYPE == "AGRICULTURAL FREEZE"] <- "FROST/FREEZE"  ## agricultural freeze likely falls under the classification frost/freeze







sort(unique(storm_data$EVTYPE))
```

Here the rows with true anomalous values are dropped.

```{r}
storm_data_dropped <- subset(storm_data, EVTYPE != "?" &
                               EVTYPE != "APACHE COUNTY"
                             )
sort(unique(storm_data_dropped$EVTYPE))
```




According to the National Weather Service Storm Data Documentation, property damage estimates *should be rounded to three significant digits, followed by an alphabetical character signifying the magnitude of the number, i.e., 1.55B for $1,550,000,000. Alphabetical characters used to signify magnitude include “K” for thousands, “M” for millions, and “B” for billions.* 

This means the PROPDMG and PROPDMGEXP columns will need to be combined to get numeric values that calculations can be performed on. But first, let's examine the unique values in the PROPDMGEXP column.

```{r check PROPDMGEXO column}
table(storm_data$PROPDMGEXP)
```

As we can see, as well as the magnitude values of "K", "M" and "B" there are 15 other anomalous values. These can be put down to data input errors. Assuming the lower case 'm' should really be an uppercase 'M', it is changed here.

```{r update PROPDMGEXP column}
storm_data$PROPDMGEXP[storm_data$PROPDMGEXP == "m"] <- "M"
```


Since the remaining anomalies only make 0.07% (321 of the 465934) of the records in the column they can be safely ignored.

Here the values in the PROPDMG column are multiplied by the exponent in the PROPDMGEXP column.

```{r multiply PROPDMG by PROPDMGEXP}
storm_data$PROPDMG = with(storm_data, ifelse(PROPDMGEXP == "K", PROPDMG * 1000,
                            ifelse(PROPDMGEXP =="M", PROPDMG * 1000000,
                                   ifelse(PROPDMGEXP == "B", PROPDMG * 1000000000,
                                          PROPDMG * 1))))
```


Turning now to crop damage, here the CROPDMGEXP column is checked for anomalies similar to those in the PROPDMGEXP column.

```{r check CROPDMGEXO column}
table(storm_data$CROPDMGEXP)
```

Again, assuming the lowercase "k" and "m" should be upper case they are changed here.

```{r update CROPDMGEXP column}
storm_data$CROPDMGEXP[storm_data$CROPDMGEXP == "k"] <- "K"
storm_data$CROPDMGEXP[storm_data$CROPDMGEXP == "m"] <- "M"
```

Here the values in the CROPDMG column are multiplied by the exponent in the CROPDMGEXP column.

```{r multiply CROPDMG by CROPDMGEXP}
storm_data$CROPDMG = with(storm_data, ifelse(CROPDMGEXP == "K", CROPDMG * 1000,
                            ifelse(CROPDMGEXP =="M", CROPDMG * 1000000,
                                   ifelse(CROPDMGEXP == "B", CROPDMG * 1000000000,
                                          CROPDMG * 1))))
```


Here the relevant columns are selected and the data is grouped by event type.

```{r select group and sum}
storm_data %>%
  select(EVTYPE, FATALITIES, INJURIES, PROPDMG, CROPDMG) %>%
  group_by(EVTYPE) %>%
  summarise(
    FATALITIES = sum(FATALITIES),
    INJURIES = sum(INJURIES),
    PROPDMG = sum(PROPDMG),
    CROPDMG = sum(CROPDMG)
  )
```












# Results
















